{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FACES = 10\n",
    "\n",
    "def detections_to_tensors(batch_detections):\n",
    "    \"\"\"\n",
    "    Convert a list of detection dictionaries to separate tensors for\n",
    "    confidences, bounding boxes, and landmarks.\n",
    "    \n",
    "    Args:\n",
    "    - detections: A list of dictionaries, each containing 'confidence', 'box', and 'keypoints'\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple of tensors: (confidences_tensor, bounding_boxes_tensor, landmarks_tensor)\n",
    "    \"\"\"\n",
    "    batch_confidences = []\n",
    "    batch_bounding_boxes = []\n",
    "    batch_landmarks = []\n",
    "    \n",
    "    for detections in batch_detections:\n",
    "        confidences = []\n",
    "        bounding_boxes = []\n",
    "        landmarks = []\n",
    "        len_detections = len(detections)\n",
    "        \n",
    "        for i in range(MAX_FACES):\n",
    "            if i >= len_detections:\n",
    "                confidences.append(0.0)\n",
    "                bounding_boxes.append([0, 0, 0, 0])\n",
    "                landmarks.append([0] * 10)\n",
    "            elif not detections[i]:\n",
    "                confidences.append(0.0)\n",
    "                bounding_boxes.append([0, 0, 0, 0])\n",
    "                landmarks.append([0] * 10)\n",
    "            else:\n",
    "                detection = detections[i]\n",
    "                print(f\"detection: {detection}\")\n",
    "        \n",
    "                # Extract confidence\n",
    "                confidences.append(detection['confidence'])\n",
    "                \n",
    "                # Extract bounding box\n",
    "                bounding_boxes.append(detection['box'])\n",
    "                \n",
    "                # Extract and flatten landmarks\n",
    "                kp = detection['keypoints']\n",
    "                landmarks_flattened = [\n",
    "                    kp['left_eye'][0], kp['left_eye'][1],\n",
    "                    kp['right_eye'][0], kp['right_eye'][1],\n",
    "                    kp['nose'][0], kp['nose'][1],\n",
    "                    kp['mouth_left'][0], kp['mouth_left'][1],\n",
    "                    kp['mouth_right'][0], kp['mouth_right'][1],\n",
    "                ]\n",
    "                landmarks.append(landmarks_flattened)\n",
    "        \n",
    "        batch_confidences.append(confidences)\n",
    "        batch_bounding_boxes.append(bounding_boxes)\n",
    "        batch_landmarks.append(landmarks)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    confidences_tensor = tf.convert_to_tensor(batch_confidences, dtype=tf.float32)\n",
    "    bounding_boxes_tensor = tf.convert_to_tensor(batch_bounding_boxes, dtype=tf.float32)\n",
    "    landmarks_tensor = tf.convert_to_tensor(batch_landmarks, dtype=tf.float32)\n",
    "    \n",
    "    return confidences_tensor, bounding_boxes_tensor, landmarks_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_labels(image_np, teacher_model):\n",
    "    \"\"\"\n",
    "    Process a single image with the teacher model to get validation labels.\n",
    "    \"\"\"\n",
    "    # This function now assumes that `image_np` is already a numpy array.\n",
    "    detection = teacher_model.detect_faces(image_np)\n",
    "    # You need to ensure detections_to_tensors is capable of handling whatever\n",
    "    # `detect_faces` returns and converts it appropriately into tensors.\n",
    "    confidences, bounding_boxes, landmarks = detections_to_tensors(detection)\n",
    "    return confidences, bounding_boxes, landmarks\n",
    "\n",
    "def tf_get_val_labels(image, teacher_model):\n",
    "    \"\"\"\n",
    "    Wrapper function to convert tensors to numpy, call the actual processing function,\n",
    "    and convert results back to tensors. Designed to be used within tf.py_function.\n",
    "    \"\"\"\n",
    "    image_np = image.numpy()  # Convert to numpy here\n",
    "    confidences, bounding_boxes, landmarks = get_val_labels(image_np, teacher_model)\n",
    "    return (confidences, bounding_boxes, landmarks)\n",
    "\n",
    "def parse_and_predict(filename, split='train', teacher_model=None):\n",
    "    \"\"\"\n",
    "    Parse images and use the teacher model to generate labels.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize the image\n",
    "\n",
    "    if teacher_model is not None:\n",
    "        # Use tf.py_function to wrap the non-TensorFlow code\n",
    "        confidences, bounding_boxes, landmarks = tf.py_function(\n",
    "            func=lambda img: tf_get_val_labels(img, teacher_model),\n",
    "            inp=[image],\n",
    "            Tout=[tf.float32, tf.float32, tf.float32]\n",
    "        )\n",
    "        labels = {\n",
    "            'confidences': confidences,\n",
    "            'bounding_boxes': bounding_boxes,\n",
    "            'landmarks': landmarks\n",
    "        }\n",
    "        return image, labels\n",
    "    return image, {'confidences': tf.zeros([MAX_FACES]), 'bounding_boxes': tf.zeros([MAX_FACES, 4]), 'landmarks': tf.zeros([MAX_FACES, 10])}\n",
    "\n",
    "\n",
    "def load_wider_face_dataset(base_directory, split='train', teacher_model=None):\n",
    "    assert split in ['train', 'test', 'val'], \"Split must be 'train', 'test', or 'val'\"\n",
    "    split_directory = os.path.join(base_directory, split)\n",
    "    \n",
    "    # Recursively find JPEG images in subfolders\n",
    "    image_paths = glob.glob(os.path.join(split_directory, '**', '*.jpg'), recursive=True)\n",
    "    \n",
    "    if not teacher_model:\n",
    "        raise ValueError(\"A teacher model must be provided for label creation\")\n",
    "\n",
    "    # Create a dataset of image paths\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    \n",
    "    # Map each image to the parse_and_predict function\n",
    "    image_dataset = image_dataset.map(lambda x: parse_and_predict(x, teacher_model),\n",
    "                                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return image_dataset.batch(2).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    \n",
    "\n",
    "def prepare_for_training(ds, batch_size=2, buffer_size=1000):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=buffer_size)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bridg\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\bridg\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_directory = 'C:/Users/bridg/tensorflow_datasets/my_wider_face'\n",
    "teacher_model = MTCNN()\n",
    "\n",
    "train_dataset = load_wider_face_dataset(base_directory, 'train', teacher_model)\n",
    "\n",
    "test_dataset = load_wider_face_dataset(base_directory, 'test', teacher_model)\n",
    "\n",
    "val_dataset = load_wider_face_dataset(base_directory, 'val', teacher_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# set a max number of faces\n",
    "# trim any faces that are below a conficence threshold\n",
    "# refactor how mtcnn data is read to grab n most confident faces\n",
    "   # set the confidences and info to zero for faces that are below the threshold\n",
    "\n",
    "# Freeze the convolutional base to prevent its weights from being updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for face and landmark detection\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Output layer for face detection (assuming binary classification: face/no face)\n",
    "confidences = Dense(MAX_FACES, activation='sigmoid', name='confidences')(x)\n",
    "\n",
    "# Predict bounding boxes for each detection\n",
    "bounding_boxes_dense = Dense(MAX_FACES * 4, activation='linear', name='bounding_boxes_dense')(x)\n",
    "bounding_boxes = Reshape((MAX_FACES, 4), name='bounding_boxes')(bounding_boxes_dense)\n",
    "\n",
    "# Predict landmarks for each detection\n",
    "landmarks_dense = Dense(MAX_FACES * 10, activation='linear', name='landmarks_dense')(x)\n",
    "landmarks = Reshape((MAX_FACES, 10), name='landmarks')(landmarks_dense)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=[confidences, bounding_boxes, landmarks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_images(dataset, num_images=9):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     for images in dataset.take(1):  # Take one batch from the dataset\n",
    "#         for i in range(num_images):\n",
    "#             ax = plt.subplot(3, 3, i + 1)\n",
    "#             plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#             plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Assuming `dataset` is your TensorFlow dataset\n",
    "# show_images(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6440/6440 [==============================] - 326s 50ms/step - loss: 6.4545e-07 - confidences_loss: 3.7382e-08 - bounding_boxes_loss: 2.9610e-07 - landmarks_loss: 3.1196e-07 - confidences_mse: 4.3077e-15 - bounding_boxes_mse: 2.9610e-07 - landmarks_mse: 3.1196e-07 - val_loss: 2.4361e-07 - val_confidences_loss: 1.0215e-08 - val_bounding_boxes_loss: 1.2554e-07 - val_landmarks_loss: 1.0786e-07 - val_confidences_mse: 1.1322e-16 - val_bounding_boxes_mse: 1.2554e-07 - val_landmarks_mse: 1.0786e-07\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'confidences': BinaryCrossentropy(),\n",
    "        'bounding_boxes': MeanSquaredError(),\n",
    "        'landmarks': MeanSquaredError()\n",
    "    },\n",
    "    loss_weights={\n",
    "        'confidences': 1.0,   # Adjust these weights to balance the contribution of each loss\n",
    "        'bounding_boxes': 1.0,\n",
    "        'landmarks': 1.0\n",
    "    },\n",
    "    metrics={\n",
    "        'confidences': ['mse'],\n",
    "        'bounding_boxes': ['mse'],\n",
    "        'landmarks': ['mse']\n",
    "    }\n",
    ")\n",
    "\n",
    "# # Iterate over each image in the batch\n",
    "# for images in train_dataset.take(1):\n",
    "#     print(f\"images: {images.shape}\")\n",
    "#     img_array = images.numpy()  # Assuming 'images' is a batch of images\n",
    "\n",
    "#     labels = []\n",
    "\n",
    "#     # Process each image in the batch individually\n",
    "#     batch_detections = []\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     for img in img_array:\n",
    "#         detections = []\n",
    "#         # Detect faces\n",
    "#         face_objs = teacher_model.detect_faces(img)\n",
    "#         # print(f\"face objs: {face_objs}\")\n",
    "#         detection = {}\n",
    "#         if len(face_objs) == 0:\n",
    "#             # detection['is_empty'] = True\n",
    "#             pass\n",
    "#         else:\n",
    "#             for face_obj in face_objs:\n",
    "#                 # print(f\"face obj: {face_obj}\")\n",
    "#                 # detection['is_empty'] = False\n",
    "#                 detection['confidence'] = face_obj['confidence']\n",
    "#                 detection['box'] = face_obj['box']\n",
    "#                 detection['keypoints'] = face_obj['keypoints']\n",
    "\n",
    "#         detections.append(detection)\n",
    "#         batch_detections.append(detections)\n",
    "\n",
    "#     confidences_labels, bounding_boxes_labels, landmarks_labels = detections_to_tensors(batch_detections)\n",
    "\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     confidences, bounding_box, landmarks = model.predict(images)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    validation_data=val_dataset,\n",
    "    validation_freq=1\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8049/8049 [==============================] - 312s 39ms/step - loss: 2.1055e-05 - confidences_loss: 3.6641e-07 - bounding_boxes_loss: 1.0495e-05 - landmarks_loss: 1.0193e-05 - confidences_mse: 1.5478e-13 - bounding_boxes_mse: 1.0495e-05 - landmarks_mse: 1.0193e-05\n",
      "Test Loss: 2.1054564058431424e-05\n",
      "Test Loss: 2.1054564058431424e-05\n"
     ]
    }
   ],
   "source": [
    "test_loss, confidence_loss, bb_loss, l_loss, c_mse, bb_mse, l_mse = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history: {'loss': [6.454491199292534e-07], 'confidences_loss': [3.738175280432188e-08], 'bounding_boxes_loss': [2.961038489956991e-07], 'landmarks_loss': [3.11964186039404e-07], 'confidences_mse': [4.307669486007049e-15], 'bounding_boxes_mse': [2.961025415970653e-07], 'landmarks_mse': [3.119632197012834e-07], 'val_loss': [2.436105717151804e-07], 'val_confidences_loss': [1.0215428503101975e-08], 'val_bounding_boxes_loss': [1.2553891792776994e-07], 'val_landmarks_loss': [1.0785628035137051e-07], 'val_confidences_mse': [1.1322384697154799e-16], 'val_bounding_boxes_mse': [1.2553888950606051e-07], 'val_landmarks_mse': [1.0785630166765259e-07]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"history: {history.history}\")\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bridg\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('lean-mtcnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, running on CPU\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.10 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1)\n",
      "ERROR: No matching distribution found for tensorflow==2.10\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " Conv (Conv2D)               (None, 112, 112, 16)         432       ['rescaling[0][0]']           \n",
      "                                                                                                  \n",
      " Conv/BatchNorm (BatchNorma  (None, 112, 112, 16)         64        ['Conv[0][0]']                \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 112, 112, 16)         0         ['Conv/BatchNorm[0][0]']      \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 112, 112, 16)         0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 112, 112, 16)         0         ['re_lu[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 112, 112, 16)         0         ['Conv/BatchNorm[0][0]',      \n",
      "                                                                     'tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise (D  (None, 112, 112, 16)         144       ['multiply[0][0]']            \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv/depthwise/Ba  (None, 112, 112, 16)         64        ['expanded_conv/depthwise[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 112, 112, 16)         0         ['expanded_conv/depthwise/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv/project (Con  (None, 112, 112, 16)         256       ['re_lu_1[0][0]']             \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " expanded_conv/project/Batc  (None, 112, 112, 16)         64        ['expanded_conv/project[0][0]'\n",
      " hNorm (BatchNormalization)                                         ]                             \n",
      "                                                                                                  \n",
      " expanded_conv/Add (Add)     (None, 112, 112, 16)         0         ['multiply[0][0]',            \n",
      "                                                                     'expanded_conv/project/BatchN\n",
      "                                                                    orm[0][0]']                   \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand (Co  (None, 112, 112, 64)         1024      ['expanded_conv/Add[0][0]']   \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_1/expand/Bat  (None, 112, 112, 64)         256       ['expanded_conv_1/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 112, 112, 64)         0         ['expanded_conv_1/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/  (None, 113, 113, 64)         0         ['re_lu_2[0][0]']             \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise   (None, 56, 56, 64)           576       ['expanded_conv_1/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_1/depthwise/  (None, 56, 56, 64)           256       ['expanded_conv_1/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 56, 56, 64)           0         ['expanded_conv_1/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_1/project (C  (None, 56, 56, 24)           1536      ['re_lu_3[0][0]']             \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_1/project/Ba  (None, 56, 56, 24)           96        ['expanded_conv_1/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand (Co  (None, 56, 56, 72)           1728      ['expanded_conv_1/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_2/expand/Bat  (None, 56, 56, 72)           288       ['expanded_conv_2/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 56, 56, 72)           0         ['expanded_conv_2/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise   (None, 56, 56, 72)           648       ['re_lu_4[0][0]']             \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_2/depthwise/  (None, 56, 56, 72)           288       ['expanded_conv_2/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 56, 56, 72)           0         ['expanded_conv_2/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_2/project (C  (None, 56, 56, 24)           1728      ['re_lu_5[0][0]']             \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_2/project/Ba  (None, 56, 56, 24)           96        ['expanded_conv_2/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_2/Add (Add)   (None, 56, 56, 24)           0         ['expanded_conv_1/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_2/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand (Co  (None, 56, 56, 72)           1728      ['expanded_conv_2/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_3/expand/Bat  (None, 56, 56, 72)           288       ['expanded_conv_3/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 56, 56, 72)           0         ['expanded_conv_3/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/  (None, 59, 59, 72)           0         ['re_lu_6[0][0]']             \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise   (None, 28, 28, 72)           1800      ['expanded_conv_3/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_3/depthwise/  (None, 28, 28, 72)           288       ['expanded_conv_3/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (None, 28, 28, 72)           0         ['expanded_conv_3/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 72)             0         ['re_lu_7[0][0]']             \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 24)             1752      ['expanded_conv_3/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 24)             0         ['expanded_conv_3/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 1, 1, 72)             1800      ['expanded_conv_3/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 1, 1, 72)             0         ['expanded_conv_3/squeeze_exci\n",
      " OpLambda)                                                          te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 1, 1, 72)             0         ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 1, 1, 72)             0         ['re_lu_8[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_3/squeeze_ex  (None, 28, 28, 72)           0         ['re_lu_7[0][0]',             \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_3/project (C  (None, 28, 28, 40)           2880      ['expanded_conv_3/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_3/project/Ba  (None, 28, 28, 40)           160       ['expanded_conv_3/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand (Co  (None, 28, 28, 120)          4800      ['expanded_conv_3/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_4/expand/Bat  (None, 28, 28, 120)          480       ['expanded_conv_4/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 28, 28, 120)          0         ['expanded_conv_4/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise   (None, 28, 28, 120)          3000      ['re_lu_9[0][0]']             \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_4/depthwise/  (None, 28, 28, 120)          480       ['expanded_conv_4/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 28, 28, 120)          0         ['expanded_conv_4/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 120)            0         ['re_lu_10[0][0]']            \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 32)             3872      ['expanded_conv_4/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 32)             0         ['expanded_conv_4/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 1, 1, 120)            3960      ['expanded_conv_4/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, 1, 1, 120)            0         ['expanded_conv_4/squeeze_exci\n",
      " OpLambda)                                                          te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 1, 1, 120)            0         ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 1, 1, 120)            0         ['re_lu_11[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_4/squeeze_ex  (None, 28, 28, 120)          0         ['re_lu_10[0][0]',            \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_2[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_4/project (C  (None, 28, 28, 40)           4800      ['expanded_conv_4/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_4/project/Ba  (None, 28, 28, 40)           160       ['expanded_conv_4/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_4/Add (Add)   (None, 28, 28, 40)           0         ['expanded_conv_3/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_4/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand (Co  (None, 28, 28, 120)          4800      ['expanded_conv_4/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_5/expand/Bat  (None, 28, 28, 120)          480       ['expanded_conv_5/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 28, 28, 120)          0         ['expanded_conv_5/expand/Batch\n",
      "                                                                    Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise   (None, 28, 28, 120)          3000      ['re_lu_12[0][0]']            \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_5/depthwise/  (None, 28, 28, 120)          480       ['expanded_conv_5/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 28, 28, 120)          0         ['expanded_conv_5/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 120)            0         ['re_lu_13[0][0]']            \n",
      " cite/AvgPool (GlobalAverag                                                                       \n",
      " ePooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 32)             3872      ['expanded_conv_5/squeeze_exci\n",
      " cite/Conv (Conv2D)                                                 te/AvgPool[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 32)             0         ['expanded_conv_5/squeeze_exci\n",
      " cite/Relu (ReLU)                                                   te/Conv[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 1, 1, 120)            3960      ['expanded_conv_5/squeeze_exci\n",
      " cite/Conv_1 (Conv2D)                                               te/Relu[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, 1, 1, 120)            0         ['expanded_conv_5/squeeze_exci\n",
      " OpLambda)                                                          te/Conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 1, 1, 120)            0         ['tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (None, 1, 1, 120)            0         ['re_lu_14[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_5/squeeze_ex  (None, 28, 28, 120)          0         ['re_lu_13[0][0]',            \n",
      " cite/Mul (Multiply)                                                 'tf.math.multiply_3[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_5/project (C  (None, 28, 28, 40)           4800      ['expanded_conv_5/squeeze_exci\n",
      " onv2D)                                                             te/Mul[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_5/project/Ba  (None, 28, 28, 40)           160       ['expanded_conv_5/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_5/Add (Add)   (None, 28, 28, 40)           0         ['expanded_conv_4/Add[0][0]', \n",
      "                                                                     'expanded_conv_5/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand (Co  (None, 28, 28, 240)          9600      ['expanded_conv_5/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_6/expand/Bat  (None, 28, 28, 240)          960       ['expanded_conv_6/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, 28, 28, 240)          0         ['expanded_conv_6/expand/Batch\n",
      " OpLambda)                                                          Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             (None, 28, 28, 240)          0         ['tf.__operators__.add_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (None, 28, 28, 240)          0         ['re_lu_15[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 28, 28, 240)          0         ['expanded_conv_6/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_4[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/  (None, 29, 29, 240)          0         ['multiply_1[0][0]']          \n",
      " pad (ZeroPadding2D)                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise   (None, 14, 14, 240)          2160      ['expanded_conv_6/depthwise/pa\n",
      " (DepthwiseConv2D)                                                  d[0][0]']                     \n",
      "                                                                                                  \n",
      " expanded_conv_6/depthwise/  (None, 14, 14, 240)          960       ['expanded_conv_6/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, 14, 14, 240)          0         ['expanded_conv_6/depthwise/Ba\n",
      " OpLambda)                                                          tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             (None, 14, 14, 240)          0         ['tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (None, 14, 14, 240)          0         ['re_lu_16[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 14, 14, 240)          0         ['expanded_conv_6/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_5[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_6/project (C  (None, 14, 14, 80)           19200     ['multiply_2[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_6/project/Ba  (None, 14, 14, 80)           320       ['expanded_conv_6/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand (Co  (None, 14, 14, 200)          16000     ['expanded_conv_6/project/Batc\n",
      " nv2D)                                                              hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_7/expand/Bat  (None, 14, 14, 200)          800       ['expanded_conv_7/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 14, 14, 200)          0         ['expanded_conv_7/expand/Batch\n",
      " OpLambda)                                                          Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (None, 14, 14, 200)          0         ['tf.__operators__.add_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (None, 14, 14, 200)          0         ['re_lu_17[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 14, 14, 200)          0         ['expanded_conv_7/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_6[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise   (None, 14, 14, 200)          1800      ['multiply_3[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_7/depthwise/  (None, 14, 14, 200)          800       ['expanded_conv_7/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 14, 14, 200)          0         ['expanded_conv_7/depthwise/Ba\n",
      " OpLambda)                                                          tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (None, 14, 14, 200)          0         ['tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLa  (None, 14, 14, 200)          0         ['re_lu_18[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)       (None, 14, 14, 200)          0         ['expanded_conv_7/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_7[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_7/project (C  (None, 14, 14, 80)           16000     ['multiply_4[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_7/project/Ba  (None, 14, 14, 80)           320       ['expanded_conv_7/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_7/Add (Add)   (None, 14, 14, 80)           0         ['expanded_conv_6/project/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'expanded_conv_7/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand (Co  (None, 14, 14, 184)          14720     ['expanded_conv_7/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_8/expand/Bat  (None, 14, 14, 184)          736       ['expanded_conv_8/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (None, 14, 14, 184)          0         ['expanded_conv_8/expand/Batch\n",
      " OpLambda)                                                          Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (None, 14, 14, 184)          0         ['tf.__operators__.add_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLa  (None, 14, 14, 184)          0         ['re_lu_19[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)       (None, 14, 14, 184)          0         ['expanded_conv_8/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_8[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise   (None, 14, 14, 184)          1656      ['multiply_5[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_8/depthwise/  (None, 14, 14, 184)          736       ['expanded_conv_8/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (None, 14, 14, 184)          0         ['expanded_conv_8/depthwise/Ba\n",
      " OpLambda)                                                          tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (None, 14, 14, 184)          0         ['tf.__operators__.add_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLa  (None, 14, 14, 184)          0         ['re_lu_20[0][0]']            \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)       (None, 14, 14, 184)          0         ['expanded_conv_8/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_9[0][0]']  \n",
      "                                                                                                  \n",
      " expanded_conv_8/project (C  (None, 14, 14, 80)           14720     ['multiply_6[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_8/project/Ba  (None, 14, 14, 80)           320       ['expanded_conv_8/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_8/Add (Add)   (None, 14, 14, 80)           0         ['expanded_conv_7/Add[0][0]', \n",
      "                                                                     'expanded_conv_8/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand (Co  (None, 14, 14, 184)          14720     ['expanded_conv_8/Add[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " expanded_conv_9/expand/Bat  (None, 14, 14, 184)          736       ['expanded_conv_9/expand[0][0]\n",
      " chNorm (BatchNormalization                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (None, 14, 14, 184)          0         ['expanded_conv_9/expand/Batch\n",
      " FOpLambda)                                                         Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             (None, 14, 14, 184)          0         ['tf.__operators__.add_10[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpL  (None, 14, 14, 184)          0         ['re_lu_21[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)       (None, 14, 14, 184)          0         ['expanded_conv_9/expand/Batch\n",
      "                                                                    Norm[0][0]',                  \n",
      "                                                                     'tf.math.multiply_10[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise   (None, 14, 14, 184)          1656      ['multiply_7[0][0]']          \n",
      " (DepthwiseConv2D)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_9/depthwise/  (None, 14, 14, 184)          736       ['expanded_conv_9/depthwise[0]\n",
      " BatchNorm (BatchNormalizat                                         [0]']                         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (None, 14, 14, 184)          0         ['expanded_conv_9/depthwise/Ba\n",
      " FOpLambda)                                                         tchNorm[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)             (None, 14, 14, 184)          0         ['tf.__operators__.add_11[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpL  (None, 14, 14, 184)          0         ['re_lu_22[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)       (None, 14, 14, 184)          0         ['expanded_conv_9/depthwise/Ba\n",
      "                                                                    tchNorm[0][0]',               \n",
      "                                                                     'tf.math.multiply_11[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_9/project (C  (None, 14, 14, 80)           14720     ['multiply_8[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_9/project/Ba  (None, 14, 14, 80)           320       ['expanded_conv_9/project[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_9/Add (Add)   (None, 14, 14, 80)           0         ['expanded_conv_8/Add[0][0]', \n",
      "                                                                     'expanded_conv_9/project/Batc\n",
      "                                                                    hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand (C  (None, 14, 14, 480)          38400     ['expanded_conv_9/Add[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_10/expand/Ba  (None, 14, 14, 480)          1920      ['expanded_conv_10/expand[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, 14, 14, 480)          0         ['expanded_conv_10/expand/Batc\n",
      " FOpLambda)                                                         hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)             (None, 14, 14, 480)          0         ['tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpL  (None, 14, 14, 480)          0         ['re_lu_23[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)       (None, 14, 14, 480)          0         ['expanded_conv_10/expand/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'tf.math.multiply_12[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise  (None, 14, 14, 480)          4320      ['multiply_9[0][0]']          \n",
      "  (DepthwiseConv2D)                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_10/depthwise  (None, 14, 14, 480)          1920      ['expanded_conv_10/depthwise[0\n",
      " /BatchNorm (BatchNormaliza                                         ][0]']                        \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, 14, 14, 480)          0         ['expanded_conv_10/depthwise/B\n",
      " FOpLambda)                                                         atchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)             (None, 14, 14, 480)          0         ['tf.__operators__.add_13[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpL  (None, 14, 14, 480)          0         ['re_lu_24[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)      (None, 14, 14, 480)          0         ['expanded_conv_10/depthwise/B\n",
      "                                                                    atchNorm[0][0]',              \n",
      "                                                                     'tf.math.multiply_13[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 480)            0         ['multiply_10[0][0]']         \n",
      " xcite/AvgPool (GlobalAvera                                                                       \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 120)            57720     ['expanded_conv_10/squeeze_exc\n",
      " xcite/Conv (Conv2D)                                                ite/AvgPool[0][0]']           \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 120)            0         ['expanded_conv_10/squeeze_exc\n",
      " xcite/Relu (ReLU)                                                  ite/Conv[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 1, 1, 480)            58080     ['expanded_conv_10/squeeze_exc\n",
      " xcite/Conv_1 (Conv2D)                                              ite/Relu[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (None, 1, 1, 480)            0         ['expanded_conv_10/squeeze_exc\n",
      " FOpLambda)                                                         ite/Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)             (None, 1, 1, 480)            0         ['tf.__operators__.add_14[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpL  (None, 1, 1, 480)            0         ['re_lu_25[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_10/squeeze_e  (None, 14, 14, 480)          0         ['multiply_10[0][0]',         \n",
      " xcite/Mul (Multiply)                                                'tf.math.multiply_14[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_10/project (  (None, 14, 14, 112)          53760     ['expanded_conv_10/squeeze_exc\n",
      " Conv2D)                                                            ite/Mul[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_10/project/B  (None, 14, 14, 112)          448       ['expanded_conv_10/project[0][\n",
      " atchNorm (BatchNormalizati                                         0]']                          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_11/expand (C  (None, 14, 14, 672)          75264     ['expanded_conv_10/project/Bat\n",
      " onv2D)                                                             chNorm[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_11/expand/Ba  (None, 14, 14, 672)          2688      ['expanded_conv_11/expand[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (None, 14, 14, 672)          0         ['expanded_conv_11/expand/Batc\n",
      " FOpLambda)                                                         hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)             (None, 14, 14, 672)          0         ['tf.__operators__.add_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpL  (None, 14, 14, 672)          0         ['re_lu_26[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)      (None, 14, 14, 672)          0         ['expanded_conv_11/expand/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'tf.math.multiply_15[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_11/depthwise  (None, 14, 14, 672)          6048      ['multiply_11[0][0]']         \n",
      "  (DepthwiseConv2D)                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_11/depthwise  (None, 14, 14, 672)          2688      ['expanded_conv_11/depthwise[0\n",
      " /BatchNorm (BatchNormaliza                                         ][0]']                        \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (None, 14, 14, 672)          0         ['expanded_conv_11/depthwise/B\n",
      " FOpLambda)                                                         atchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)             (None, 14, 14, 672)          0         ['tf.__operators__.add_16[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpL  (None, 14, 14, 672)          0         ['re_lu_27[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_12 (Multiply)      (None, 14, 14, 672)          0         ['expanded_conv_11/depthwise/B\n",
      "                                                                    atchNorm[0][0]',              \n",
      "                                                                     'tf.math.multiply_16[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_11/squeeze_e  (None, 1, 1, 672)            0         ['multiply_12[0][0]']         \n",
      " xcite/AvgPool (GlobalAvera                                                                       \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " expanded_conv_11/squeeze_e  (None, 1, 1, 168)            113064    ['expanded_conv_11/squeeze_exc\n",
      " xcite/Conv (Conv2D)                                                ite/AvgPool[0][0]']           \n",
      "                                                                                                  \n",
      " expanded_conv_11/squeeze_e  (None, 1, 1, 168)            0         ['expanded_conv_11/squeeze_exc\n",
      " xcite/Relu (ReLU)                                                  ite/Conv[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv_11/squeeze_e  (None, 1, 1, 672)            113568    ['expanded_conv_11/squeeze_exc\n",
      " xcite/Conv_1 (Conv2D)                                              ite/Relu[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (None, 1, 1, 672)            0         ['expanded_conv_11/squeeze_exc\n",
      " FOpLambda)                                                         ite/Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)             (None, 1, 1, 672)            0         ['tf.__operators__.add_17[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpL  (None, 1, 1, 672)            0         ['re_lu_28[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_11/squeeze_e  (None, 14, 14, 672)          0         ['multiply_12[0][0]',         \n",
      " xcite/Mul (Multiply)                                                'tf.math.multiply_17[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_11/project (  (None, 14, 14, 112)          75264     ['expanded_conv_11/squeeze_exc\n",
      " Conv2D)                                                            ite/Mul[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_11/project/B  (None, 14, 14, 112)          448       ['expanded_conv_11/project[0][\n",
      " atchNorm (BatchNormalizati                                         0]']                          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_11/Add (Add)  (None, 14, 14, 112)          0         ['expanded_conv_10/project/Bat\n",
      "                                                                    chNorm[0][0]',                \n",
      "                                                                     'expanded_conv_11/project/Bat\n",
      "                                                                    chNorm[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_12/expand (C  (None, 14, 14, 672)          75264     ['expanded_conv_11/Add[0][0]']\n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_12/expand/Ba  (None, 14, 14, 672)          2688      ['expanded_conv_12/expand[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (None, 14, 14, 672)          0         ['expanded_conv_12/expand/Batc\n",
      " FOpLambda)                                                         hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)             (None, 14, 14, 672)          0         ['tf.__operators__.add_18[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpL  (None, 14, 14, 672)          0         ['re_lu_29[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_13 (Multiply)      (None, 14, 14, 672)          0         ['expanded_conv_12/expand/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'tf.math.multiply_18[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_12/depthwise  (None, 17, 17, 672)          0         ['multiply_13[0][0]']         \n",
      " /pad (ZeroPadding2D)                                                                             \n",
      "                                                                                                  \n",
      " expanded_conv_12/depthwise  (None, 7, 7, 672)            16800     ['expanded_conv_12/depthwise/p\n",
      "  (DepthwiseConv2D)                                                 ad[0][0]']                    \n",
      "                                                                                                  \n",
      " expanded_conv_12/depthwise  (None, 7, 7, 672)            2688      ['expanded_conv_12/depthwise[0\n",
      " /BatchNorm (BatchNormaliza                                         ][0]']                        \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (None, 7, 7, 672)            0         ['expanded_conv_12/depthwise/B\n",
      " FOpLambda)                                                         atchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)             (None, 7, 7, 672)            0         ['tf.__operators__.add_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpL  (None, 7, 7, 672)            0         ['re_lu_30[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_14 (Multiply)      (None, 7, 7, 672)            0         ['expanded_conv_12/depthwise/B\n",
      "                                                                    atchNorm[0][0]',              \n",
      "                                                                     'tf.math.multiply_19[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_12/squeeze_e  (None, 1, 1, 672)            0         ['multiply_14[0][0]']         \n",
      " xcite/AvgPool (GlobalAvera                                                                       \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " expanded_conv_12/squeeze_e  (None, 1, 1, 168)            113064    ['expanded_conv_12/squeeze_exc\n",
      " xcite/Conv (Conv2D)                                                ite/AvgPool[0][0]']           \n",
      "                                                                                                  \n",
      " expanded_conv_12/squeeze_e  (None, 1, 1, 168)            0         ['expanded_conv_12/squeeze_exc\n",
      " xcite/Relu (ReLU)                                                  ite/Conv[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv_12/squeeze_e  (None, 1, 1, 672)            113568    ['expanded_conv_12/squeeze_exc\n",
      " xcite/Conv_1 (Conv2D)                                              ite/Relu[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (None, 1, 1, 672)            0         ['expanded_conv_12/squeeze_exc\n",
      " FOpLambda)                                                         ite/Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)             (None, 1, 1, 672)            0         ['tf.__operators__.add_20[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpL  (None, 1, 1, 672)            0         ['re_lu_31[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_12/squeeze_e  (None, 7, 7, 672)            0         ['multiply_14[0][0]',         \n",
      " xcite/Mul (Multiply)                                                'tf.math.multiply_20[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_12/project (  (None, 7, 7, 160)            107520    ['expanded_conv_12/squeeze_exc\n",
      " Conv2D)                                                            ite/Mul[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_12/project/B  (None, 7, 7, 160)            640       ['expanded_conv_12/project[0][\n",
      " atchNorm (BatchNormalizati                                         0]']                          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_13/expand (C  (None, 7, 7, 960)            153600    ['expanded_conv_12/project/Bat\n",
      " onv2D)                                                             chNorm[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_13/expand/Ba  (None, 7, 7, 960)            3840      ['expanded_conv_13/expand[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (None, 7, 7, 960)            0         ['expanded_conv_13/expand/Batc\n",
      " FOpLambda)                                                         hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)             (None, 7, 7, 960)            0         ['tf.__operators__.add_21[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpL  (None, 7, 7, 960)            0         ['re_lu_32[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_15 (Multiply)      (None, 7, 7, 960)            0         ['expanded_conv_13/expand/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'tf.math.multiply_21[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_13/depthwise  (None, 7, 7, 960)            24000     ['multiply_15[0][0]']         \n",
      "  (DepthwiseConv2D)                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_13/depthwise  (None, 7, 7, 960)            3840      ['expanded_conv_13/depthwise[0\n",
      " /BatchNorm (BatchNormaliza                                         ][0]']                        \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (None, 7, 7, 960)            0         ['expanded_conv_13/depthwise/B\n",
      " FOpLambda)                                                         atchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)             (None, 7, 7, 960)            0         ['tf.__operators__.add_22[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpL  (None, 7, 7, 960)            0         ['re_lu_33[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_16 (Multiply)      (None, 7, 7, 960)            0         ['expanded_conv_13/depthwise/B\n",
      "                                                                    atchNorm[0][0]',              \n",
      "                                                                     'tf.math.multiply_22[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_13/squeeze_e  (None, 1, 1, 960)            0         ['multiply_16[0][0]']         \n",
      " xcite/AvgPool (GlobalAvera                                                                       \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " expanded_conv_13/squeeze_e  (None, 1, 1, 240)            230640    ['expanded_conv_13/squeeze_exc\n",
      " xcite/Conv (Conv2D)                                                ite/AvgPool[0][0]']           \n",
      "                                                                                                  \n",
      " expanded_conv_13/squeeze_e  (None, 1, 1, 240)            0         ['expanded_conv_13/squeeze_exc\n",
      " xcite/Relu (ReLU)                                                  ite/Conv[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv_13/squeeze_e  (None, 1, 1, 960)            231360    ['expanded_conv_13/squeeze_exc\n",
      " xcite/Conv_1 (Conv2D)                                              ite/Relu[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (None, 1, 1, 960)            0         ['expanded_conv_13/squeeze_exc\n",
      " FOpLambda)                                                         ite/Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)             (None, 1, 1, 960)            0         ['tf.__operators__.add_23[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpL  (None, 1, 1, 960)            0         ['re_lu_34[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_13/squeeze_e  (None, 7, 7, 960)            0         ['multiply_16[0][0]',         \n",
      " xcite/Mul (Multiply)                                                'tf.math.multiply_23[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_13/project (  (None, 7, 7, 160)            153600    ['expanded_conv_13/squeeze_exc\n",
      " Conv2D)                                                            ite/Mul[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_13/project/B  (None, 7, 7, 160)            640       ['expanded_conv_13/project[0][\n",
      " atchNorm (BatchNormalizati                                         0]']                          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_13/Add (Add)  (None, 7, 7, 160)            0         ['expanded_conv_12/project/Bat\n",
      "                                                                    chNorm[0][0]',                \n",
      "                                                                     'expanded_conv_13/project/Bat\n",
      "                                                                    chNorm[0][0]']                \n",
      "                                                                                                  \n",
      " expanded_conv_14/expand (C  (None, 7, 7, 960)            153600    ['expanded_conv_13/Add[0][0]']\n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_14/expand/Ba  (None, 7, 7, 960)            3840      ['expanded_conv_14/expand[0][0\n",
      " tchNorm (BatchNormalizatio                                         ]']                           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (T  (None, 7, 7, 960)            0         ['expanded_conv_14/expand/Batc\n",
      " FOpLambda)                                                         hNorm[0][0]']                 \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)             (None, 7, 7, 960)            0         ['tf.__operators__.add_24[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpL  (None, 7, 7, 960)            0         ['re_lu_35[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_17 (Multiply)      (None, 7, 7, 960)            0         ['expanded_conv_14/expand/Batc\n",
      "                                                                    hNorm[0][0]',                 \n",
      "                                                                     'tf.math.multiply_24[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_14/depthwise  (None, 7, 7, 960)            24000     ['multiply_17[0][0]']         \n",
      "  (DepthwiseConv2D)                                                                               \n",
      "                                                                                                  \n",
      " expanded_conv_14/depthwise  (None, 7, 7, 960)            3840      ['expanded_conv_14/depthwise[0\n",
      " /BatchNorm (BatchNormaliza                                         ][0]']                        \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (T  (None, 7, 7, 960)            0         ['expanded_conv_14/depthwise/B\n",
      " FOpLambda)                                                         atchNorm[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)             (None, 7, 7, 960)            0         ['tf.__operators__.add_25[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpL  (None, 7, 7, 960)            0         ['re_lu_36[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_18 (Multiply)      (None, 7, 7, 960)            0         ['expanded_conv_14/depthwise/B\n",
      "                                                                    atchNorm[0][0]',              \n",
      "                                                                     'tf.math.multiply_25[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_14/squeeze_e  (None, 1, 1, 960)            0         ['multiply_18[0][0]']         \n",
      " xcite/AvgPool (GlobalAvera                                                                       \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " expanded_conv_14/squeeze_e  (None, 1, 1, 240)            230640    ['expanded_conv_14/squeeze_exc\n",
      " xcite/Conv (Conv2D)                                                ite/AvgPool[0][0]']           \n",
      "                                                                                                  \n",
      " expanded_conv_14/squeeze_e  (None, 1, 1, 240)            0         ['expanded_conv_14/squeeze_exc\n",
      " xcite/Relu (ReLU)                                                  ite/Conv[0][0]']              \n",
      "                                                                                                  \n",
      " expanded_conv_14/squeeze_e  (None, 1, 1, 960)            231360    ['expanded_conv_14/squeeze_exc\n",
      " xcite/Conv_1 (Conv2D)                                              ite/Relu[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (T  (None, 1, 1, 960)            0         ['expanded_conv_14/squeeze_exc\n",
      " FOpLambda)                                                         ite/Conv_1[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)             (None, 1, 1, 960)            0         ['tf.__operators__.add_26[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpL  (None, 1, 1, 960)            0         ['re_lu_37[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " expanded_conv_14/squeeze_e  (None, 7, 7, 960)            0         ['multiply_18[0][0]',         \n",
      " xcite/Mul (Multiply)                                                'tf.math.multiply_26[0][0]'] \n",
      "                                                                                                  \n",
      " expanded_conv_14/project (  (None, 7, 7, 160)            153600    ['expanded_conv_14/squeeze_exc\n",
      " Conv2D)                                                            ite/Mul[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_14/project/B  (None, 7, 7, 160)            640       ['expanded_conv_14/project[0][\n",
      " atchNorm (BatchNormalizati                                         0]']                          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " expanded_conv_14/Add (Add)  (None, 7, 7, 160)            0         ['expanded_conv_13/Add[0][0]',\n",
      "                                                                     'expanded_conv_14/project/Bat\n",
      "                                                                    chNorm[0][0]']                \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 7, 7, 960)            153600    ['expanded_conv_14/Add[0][0]']\n",
      "                                                                                                  \n",
      " Conv_1/BatchNorm (BatchNor  (None, 7, 7, 960)            3840      ['Conv_1[0][0]']              \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (T  (None, 7, 7, 960)            0         ['Conv_1/BatchNorm[0][0]']    \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)             (None, 7, 7, 960)            0         ['tf.__operators__.add_27[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_27 (TFOpL  (None, 7, 7, 960)            0         ['re_lu_38[0][0]']            \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multiply_19 (Multiply)      (None, 7, 7, 960)            0         ['Conv_1/BatchNorm[0][0]',    \n",
      "                                                                     'tf.math.multiply_27[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 960)                  0         ['multiply_19[0][0]']         \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 984064    ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " bounding_boxes (Dense)      (None, 40)                   41000     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " landmarks (Dense)           (None, 100)                  102500    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " detection (Dense)           (None, 10)                   10250     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 10, 4)                0         ['bounding_boxes[0][0]']      \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 10, 10)               0         ['landmarks[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4134166 (15.77 MB)\n",
      "Trainable params: 1137814 (4.34 MB)\n",
      "Non-trainable params: 2996352 (11.43 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detections: [{'box': [0, 0, 0, 0], 'confidence': 0.6748742461204529, 'keypoints': {'left_eye': (-0.73534316, 1.0557722), 'right_eye': (0.52684826, 0.087934226), 'nose': (-3.246008, 1.0227318), 'mouth_left': (-0.070850015, -2.3160443), 'mouth_right': (-0.30880076, -1.1930287)}}, {'box': [0, 0, 0, 0], 'confidence': 0.662733256816864, 'keypoints': {'left_eye': (-0.46789718, 1.1963675), 'right_eye': (2.265353, -0.6215133), 'nose': (-0.5917515, 1.2513131), 'mouth_left': (0.2775367, -1.4230711), 'mouth_right': (1.2971957, -0.44156244)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7612593173980713, 'keypoints': {'left_eye': (0.02128604, -0.1444282), 'right_eye': (0.9780227, -0.062327206), 'nose': (-0.7947538, -0.24396026), 'mouth_left': (-0.80730915, -0.39987165), 'mouth_right': (-0.243312, -0.40480956)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7261316776275635, 'keypoints': {'left_eye': (0.19468048, -0.12398183), 'right_eye': (0.3937503, 0.80306935), 'nose': (-2.1229439, 1.3268812), 'mouth_left': (0.37262142, -1.9344918), 'mouth_right': (-0.009756461, -1.6687906)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6112657189369202, 'keypoints': {'left_eye': (-1.4376838, -0.13405369), 'right_eye': (0.9454672, -1.0054946), 'nose': (-1.2796795, 0.7237004), 'mouth_left': (0.17286426, -1.6581006), 'mouth_right': (-0.051362723, -1.3805331)}}, {'box': [0, 0, 0, 0], 'confidence': 0.43956613540649414, 'keypoints': {'left_eye': (0.25797448, 0.10887772), 'right_eye': (1.742039, 0.047320604), 'nose': (-2.6878638, 1.2664157), 'mouth_left': (-0.6220403, -0.83493066), 'mouth_right': (0.64588857, 0.46361288)}}, {'box': [0, 0, 0, 0], 'confidence': 0.45596566796302795, 'keypoints': {'left_eye': (-0.48110017, -0.054014698), 'right_eye': (0.81094515, 0.20306033), 'nose': (-1.3471062, 1.043869), 'mouth_left': (-0.45052552, -0.91372937), 'mouth_right': (0.38716, 0.31470937)}}, {'box': [0, 0, 0, 0], 'confidence': 0.3327430784702301, 'keypoints': {'left_eye': (-0.8909421, -0.10495494), 'right_eye': (0.78482074, 0.22628881), 'nose': (-1.6374907, 1.1686583), 'mouth_left': (-0.23000596, -2.0365424), 'mouth_right': (0.8789638, -1.7195067)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6887228488922119, 'keypoints': {'left_eye': (-1.0079868, -0.5448346), 'right_eye': (0.47385538, 0.15579048), 'nose': (-2.1194272, 0.955676), 'mouth_left': (1.0999314, -1.1255065), 'mouth_right': (-0.1230492, -1.2754079)}}, {'box': [0, 0, 0, 0], 'confidence': 0.26138707995414734, 'keypoints': {'left_eye': (-2.0817835, 0.8285319), 'right_eye': (2.9650826, -0.3966746), 'nose': (-1.7730532, -0.1268357), 'mouth_left': (-0.38797796, -2.1397014), 'mouth_right': (0.32318836, -1.3868986)}}, {'box': [0, 0, 0, 0], 'confidence': 0.44208064675331116, 'keypoints': {'left_eye': (-1.4223311, 0.5183261), 'right_eye': (0.92046547, 0.36272493), 'nose': (-2.7218766, 0.8806597), 'mouth_left': (-0.5534946, -1.6414999), 'mouth_right': (0.059157312, -0.39896873)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6162046194076538, 'keypoints': {'left_eye': (-0.7164855, -0.3229618), 'right_eye': (1.4644511, 1.094023), 'nose': (-1.5458885, 1.6753731), 'mouth_left': (0.7595, -1.9355742), 'mouth_right': (0.60619366, -1.6566324)}}, {'box': [0, 0, 0, 0], 'confidence': 0.5007038712501526, 'keypoints': {'left_eye': (-0.8981524, 0.2851976), 'right_eye': (2.0749166, -0.25473645), 'nose': (-2.055313, 0.47512257), 'mouth_left': (1.4844327, -1.8432792), 'mouth_right': (0.45787084, -0.9326553)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6677223443984985, 'keypoints': {'left_eye': (0.26903564, 0.7264953), 'right_eye': (2.31631, -0.20283666), 'nose': (-2.39993, 0.3170562), 'mouth_left': (0.31730622, -2.4194305), 'mouth_right': (-0.6484506, -1.0925173)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6510516405105591, 'keypoints': {'left_eye': (0.4056281, -0.46656206), 'right_eye': (0.69371736, 0.6295694), 'nose': (-1.0539335, 1.3557016), 'mouth_left': (1.024978, -1.1571667), 'mouth_right': (0.27583224, -2.5201042)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7634016871452332, 'keypoints': {'left_eye': (-0.75844675, 1.5011079), 'right_eye': (1.3022864, 0.034379803), 'nose': (-2.9678924, 0.88230073), 'mouth_left': (-0.18527794, -2.5490048), 'mouth_right': (-1.0788337, -1.2654924)}}, {'box': [0, 0, 0, 0], 'confidence': 0.8083810210227966, 'keypoints': {'left_eye': (0.12408441, 0.3159696), 'right_eye': (1.3021337, -0.24238002), 'nose': (-1.8894472, 0.57253164), 'mouth_left': (-0.19124562, -1.569947), 'mouth_right': (1.5067283, -2.5788105)}}, {'box': [0, 0, 0, 0], 'confidence': 0.22409279644489288, 'keypoints': {'left_eye': (-0.7106621, 0.31891042), 'right_eye': (2.041935, 0.123496056), 'nose': (-0.604337, 0.05501657), 'mouth_left': (-0.46236682, -0.93050236), 'mouth_right': (-0.5908302, -0.50541604)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6429218649864197, 'keypoints': {'left_eye': (0.8314836, 0.5336419), 'right_eye': (0.994622, -0.55376697), 'nose': (-1.3113993, 1.2257055), 'mouth_left': (0.20948464, -1.9082013), 'mouth_right': (-0.9077283, -0.65188754)}}, {'box': [0, 0, 0, 0], 'confidence': 0.8969323039054871, 'keypoints': {'left_eye': (-0.3491745, -0.77068746), 'right_eye': (0.9141724, 1.1773255), 'nose': (-1.7386501, -0.014859706), 'mouth_left': (-0.6711997, -1.1837105), 'mouth_right': (-0.03721135, -1.170072)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7750704288482666, 'keypoints': {'left_eye': (-0.35558227, 3.3539774), 'right_eye': (1.1430913, -0.8557833), 'nose': (-0.5160624, 0.5252401), 'mouth_left': (1.4499307, -0.18910882), 'mouth_right': (-0.93902135, -0.7960827)}}, {'box': [0, 0, 0, 0], 'confidence': 0.8036332726478577, 'keypoints': {'left_eye': (-0.57090366, 0.19525385), 'right_eye': (1.4522698, 0.53823686), 'nose': (-2.520535, 0.7806097), 'mouth_left': (-0.18835843, -2.103738), 'mouth_right': (-0.12026468, -1.3040837)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7937236428260803, 'keypoints': {'left_eye': (-0.1102094, -0.13833255), 'right_eye': (0.16710642, 0.64867634), 'nose': (-1.1720443, 0.01630336), 'mouth_left': (-0.02336435, -1.401716), 'mouth_right': (0.79992783, -1.1465005)}}, {'box': [0, 0, 0, 0], 'confidence': 0.5418329834938049, 'keypoints': {'left_eye': (0.3170822, 0.8031453), 'right_eye': (0.122058064, 0.4389605), 'nose': (-0.75579894, 1.3108217), 'mouth_left': (-1.5569513, -0.37622035), 'mouth_right': (0.6614735, -0.579587)}}, {'box': [0, 0, 0, 0], 'confidence': 0.4066491723060608, 'keypoints': {'left_eye': (-1.342586, 0.24617955), 'right_eye': (0.59812474, 1.2999786), 'nose': (-1.0304201, 0.7791197), 'mouth_left': (0.1895448, -0.6043046), 'mouth_right': (0.23198086, -1.0792239)}}, {'box': [0, 0, 0, 0], 'confidence': 0.6315093040466309, 'keypoints': {'left_eye': (-0.37820798, 0.30032268), 'right_eye': (-0.36450517, 0.16434371), 'nose': (-2.6078386, 0.9522995), 'mouth_left': (0.2733035, -2.0981436), 'mouth_right': (-0.8825002, -2.2394173)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7679756283760071, 'keypoints': {'left_eye': (-0.33176193, -0.47868887), 'right_eye': (0.97607106, 0.4909075), 'nose': (-1.8264654, 1.1663303), 'mouth_left': (0.40391463, -0.93893725), 'mouth_right': (0.09386648, -0.78133535)}}, {'box': [0, 0, 0, 0], 'confidence': 0.7475014925003052, 'keypoints': {'left_eye': (-0.3774311, 0.7491859), 'right_eye': (0.17327793, 0.40230832), 'nose': (-1.2746692, -0.17657539), 'mouth_left': (0.14843279, -0.39118445), 'mouth_right': (0.778028, -0.34455544)}}, {'box': [0, 0, 0, 0], 'confidence': 0.4190661609172821, 'keypoints': {'left_eye': (-0.19434883, 0.16757837), 'right_eye': (1.592175, -0.61957973), 'nose': (-1.334296, 0.31065306), 'mouth_left': (-0.35070005, -1.1454306), 'mouth_right': (-0.43045896, -0.20537475)}}, {'box': [0, 0, 0, 0], 'confidence': 0.5351845622062683, 'keypoints': {'left_eye': (0.8510463, 0.9252754), 'right_eye': (0.62585545, -0.27070066), 'nose': (-1.6858616, 0.35231534), 'mouth_left': (-0.21385603, -1.3673733), 'mouth_right': (0.38269535, -0.80226666)}}, {'box': [0, 0, 0, 0], 'confidence': 0.4229130446910858, 'keypoints': {'left_eye': (-0.13112305, -0.53981864), 'right_eye': (0.90451014, 0.10645044), 'nose': (-3.051505, 0.60885894), 'mouth_left': (-1.2859052, -1.5442549), 'mouth_right': (-0.57167697, 0.5641434)}}, {'box': [0, 0, 0, 0], 'confidence': 0.8828781247138977, 'keypoints': {'left_eye': (-0.18554488, -1.1352165), 'right_eye': (1.1226485, 1.0341074), 'nose': (-2.974544, 1.0071846), 'mouth_left': (-0.60380226, -1.4423974), 'mouth_right': (0.17357188, -0.8182271)}}]\n",
    "\n",
    "\n",
    "labels: [[], [{'box': [24, 30, 18, 27], 'confidence': 0.9997275471687317, 'keypoints': {'left_eye': (30, 40), 'right_eye': (38, 42), 'nose': (34, 46), 'mouth_left': (28, 49), 'mouth_right': (37, 51)}}, {'box': [145, 42, 20, 30], 'confidence': 0.9990147352218628, 'keypoints': {'left_eye': (151, 53), 'right_eye': (160, 54), 'nose': (154, 60), 'mouth_left': (150, 65), 'mouth_right': (157, 66)}}, {'box': [73, 47, 19, 28], 'confidence': 0.9989433884620667, 'keypoints': {'left_eye': (80, 57), 'right_eye': (88, 59), 'nose': (84, 64), 'mouth_left': (79, 67), 'mouth_right': (87, 69)}}, {'box': [115, 52, 17, 28], 'confidence': 0.9985287189483643, 'keypoints': {'left_eye': (118, 62), 'right_eye': (126, 62), 'nose': (121, 67), 'mouth_left': (118, 72), 'mouth_right': (127, 72)}}, {'box': [178, 53, 17, 26], 'confidence': 0.9978204965591431, 'keypoints': {'left_eye': (181, 62), 'right_eye': (190, 63), 'nose': (185, 68), 'mouth_left': (181, 72), 'mouth_right': (189, 73)}}], [{'box': [81, 43, 17, 29], 'confidence': 0.973102331161499, 'keypoints': {'left_eye': (91, 53), 'right_eye': (97, 52), 'nose': (97, 59), 'mouth_left': (92, 65), 'mouth_right': (96, 65)}}, {'box': [129, 16, 20, 34], 'confidence': 0.9348683953285217, 'keypoints': {'left_eye': (133, 29), 'right_eye': (140, 26), 'nose': (136, 35), 'mouth_left': (138, 44), 'mouth_right': (142, 42)}}], [], [], [{'box': [92, 39, 14, 19], 'confidence': 0.998066246509552, 'keypoints': {'left_eye': (95, 45), 'right_eye': (103, 45), 'nose': (99, 51), 'mouth_left': (96, 54), 'mouth_right': (103, 53)}}, {'box': [179, 35, 15, 20], 'confidence': 0.9970511198043823, 'keypoints': {'left_eye': (182, 40), 'right_eye': (190, 40), 'nose': (185, 46), 'mouth_left': (183, 49), 'mouth_right': (190, 49)}}, {'box': [58, 40, 15, 23], 'confidence': 0.9963812828063965, 'keypoints': {'left_eye': (62, 49), 'right_eye': (70, 49), 'nose': (66, 54), 'mouth_left': (62, 57), 'mouth_right': (69, 57)}}, {'box': [29, 49, 14, 22], 'confidence': 0.9856202602386475, 'keypoints': {'left_eye': (34, 56), 'right_eye': (41, 57), 'nose': (38, 63), 'mouth_left': (33, 66), 'mouth_right': (39, 66)}}, {'box': [138, 35, 17, 28], 'confidence': 0.9763843417167664, 'keypoints': {'left_eye': (144, 46), 'right_eye': (152, 47), 'nose': (148, 53), 'mouth_left': (143, 56), 'mouth_right': (150, 57)}}], [], [{'box': [138, 38, 14, 20], 'confidence': 0.9882583022117615, 'keypoints': {'left_eye': (140, 45), 'right_eye': (147, 43), 'nose': (144, 49), 'mouth_left': (142, 53), 'mouth_right': (148, 51)}}, {'box': [35, 28, 15, 25], 'confidence': 0.9718230962753296, 'keypoints': {'left_eye': (39, 37), 'right_eye': (47, 38), 'nose': (43, 43), 'mouth_left': (39, 46), 'mouth_right': (45, 47)}}, {'box': [171, 36, 14, 25], 'confidence': 0.9571990370750427, 'keypoints': {'left_eye': (173, 46), 'right_eye': (180, 45), 'nose': (175, 52), 'mouth_left': (173, 56), 'mouth_right': (179, 55)}}, {'box': [101, 31, 15, 23], 'confidence': 0.942952573299408, 'keypoints': {'left_eye': (104, 39), 'right_eye': (112, 39), 'nose': (108, 45), 'mouth_left': (105, 49), 'mouth_right': (111, 49)}}, {'box': [74, 25, 16, 27], 'confidence': 0.871976375579834, 'keypoints': {'left_eye': (79, 36), 'right_eye': (87, 37), 'nose': (84, 42), 'mouth_left': (79, 46), 'mouth_right': (85, 46)}}], [], [{'box': [122, 45, 7, 11], 'confidence': 0.9735006093978882, 'keypoints': {'left_eye': (124, 50), 'right_eye': (128, 49), 'nose': (126, 52), 'mouth_left': (125, 54), 'mouth_right': (128, 54)}}, {'box': [87, 57, 9, 13], 'confidence': 0.9728569388389587, 'keypoints': {'left_eye': (90, 62), 'right_eye': (95, 63), 'nose': (92, 67), 'mouth_left': (89, 69), 'mouth_right': (93, 69)}}, {'box': [113, 101, 12, 16], 'confidence': 0.862289309501648, 'keypoints': {'left_eye': (116, 106), 'right_eye': (122, 106), 'nose': (119, 109), 'mouth_left': (116, 112), 'mouth_right': (121, 112)}}, {'box': [180, 36, 12, 17], 'confidence': 0.7790029644966125, 'keypoints': {'left_eye': (182, 42), 'right_eye': (186, 41), 'nose': (183, 45), 'mouth_left': (183, 49), 'mouth_right': (187, 48)}}, {'box': [39, 38, 11, 14], 'confidence': 0.7031712532043457, 'keypoints': {'left_eye': (44, 41), 'right_eye': (49, 42), 'nose': (47, 46), 'mouth_left': (43, 48), 'mouth_right': (47, 48)}}], [], [], [], [], [], [], [], [{'box': [12, 58, 22, 32], 'confidence': 0.9999390840530396, 'keypoints': {'left_eye': (23, 70), 'right_eye': (32, 70), 'nose': (31, 78), 'mouth_left': (25, 83), 'mouth_right': (31, 83)}}, {'box': [87, 56, 13, 21], 'confidence': 0.9996486902236938, 'keypoints': {'left_eye': (93, 63), 'right_eye': (99, 64), 'nose': (97, 69), 'mouth_left': (92, 72), 'mouth_right': (97, 72)}}, {'box': [116, 47, 11, 17], 'confidence': 0.9858732223510742, 'keypoints': {'left_eye': (119, 53), 'right_eye': (125, 53), 'nose': (122, 57), 'mouth_left': (120, 61), 'mouth_right': (124, 60)}}, {'box': [191, 43, 9, 13], 'confidence': 0.9697521328926086, 'keypoints': {'left_eye': (192, 49), 'right_eye': (196, 47), 'nose': (194, 51), 'mouth_left': (194, 54), 'mouth_right': (197, 53)}}], [{'box': [91, 113, 8, 10], 'confidence': 0.9931857585906982, 'keypoints': {'left_eye': (92, 116), 'right_eye': (97, 115), 'nose': (95, 118), 'mouth_left': (93, 121), 'mouth_right': (97, 120)}}], [], [], [], [{'box': [208, 54, 17, 18], 'confidence': 0.997380793094635, 'keypoints': {'left_eye': (211, 60), 'right_eye': (218, 59), 'nose': (213, 64), 'mouth_left': (212, 68), 'mouth_right': (218, 68)}}, {'box': [138, 27, 25, 28], 'confidence': 0.9966952800750732, 'keypoints': {'left_eye': (141, 37), 'right_eye': (150, 38), 'nose': (141, 43), 'mouth_left': (139, 49), 'mouth_right': (146, 49)}}, {'box': [34, 38, 18, 19], 'confidence': 0.9934418201446533, 'keypoints': {'left_eye': (36, 45), 'right_eye': (43, 45), 'nose': (37, 50), 'mouth_left': (37, 55), 'mouth_right': (43, 54)}}], [{'box': [29, 12, 37, 54], 'confidence': 0.9999991655349731, 'keypoints': {'left_eye': (53, 33), 'right_eye': (64, 34), 'nose': (65, 44), 'mouth_left': (51, 51), 'mouth_right': (62, 52)}}, {'box': [159, 23, 31, 50], 'confidence': 0.9999954700469971, 'keypoints': {'left_eye': (162, 42), 'right_eye': (169, 43), 'nose': (159, 53), 'mouth_left': (164, 62), 'mouth_right': (171, 62)}}], [], [], [], [{'box': [82, 60, 43, 70], 'confidence': 0.9998668432235718, 'keypoints': {'left_eye': (112, 88), 'right_eye': (124, 87), 'nose': (129, 98), 'mouth_left': (114, 113), 'mouth_right': (125, 111)}}, {'box': [48, 84, 16, 23], 'confidence': 0.9290136694908142, 'keypoints': {'left_eye': (55, 91), 'right_eye': (62, 91), 'nose': (60, 96), 'mouth_left': (56, 102), 'mouth_right': (61, 102)}}, {'box': [176, 170, 24, 45], 'confidence': 0.8331894278526306, 'keypoints': {'left_eye': (190, 187), 'right_eye': (198, 188), 'nose': (199, 196), 'mouth_left': (191, 206), 'mouth_right': (197, 206)}}], [{'box': [177, 34, 20, 28], 'confidence': 0.9993168115615845, 'keypoints': {'left_eye': (179, 45), 'right_eye': (188, 44), 'nose': (182, 51), 'mouth_left': (181, 56), 'mouth_right': (188, 55)}}, {'box': [9, 46, 19, 26], 'confidence': 0.999021053314209, 'keypoints': {'left_eye': (15, 54), 'right_eye': (24, 55), 'nose': (21, 61), 'mouth_left': (14, 64), 'mouth_right': (23, 64)}}, {'box': [84, 40, 15, 21], 'confidence': 0.998915433883667, 'keypoints': {'left_eye': (90, 48), 'right_eye': (97, 47), 'nose': (95, 53), 'mouth_left': (90, 56), 'mouth_right': (96, 55)}}, {'box': [116, 33, 15, 24], 'confidence': 0.9959874749183655, 'keypoints': {'left_eye': (122, 43), 'right_eye': (129, 43), 'nose': (127, 49), 'mouth_left': (121, 52), 'mouth_right': (127, 52)}}, {'box': [45, 52, 18, 25], 'confidence': 0.9835267663002014, 'keypoints': {'left_eye': (51, 63), 'right_eye': (59, 61), 'nose': (57, 68), 'mouth_left': (51, 72), 'mouth_right': (60, 70)}}, {'box': [145, 40, 18, 23], 'confidence': 0.9813764691352844, 'keypoints': {'left_eye': (146, 51), 'right_eye': (153, 48), 'nose': (149, 55), 'mouth_left': (150, 60), 'mouth_right': (156, 57)}}], [{'box': [85, 60, 51, 65], 'confidence': 0.999955415725708, 'keypoints': {'left_eye': (97, 81), 'right_eye': (121, 84), 'nose': (104, 97), 'mouth_left': (95, 105), 'mouth_right': (118, 109)}}, {'box': [52, 109, 10, 14], 'confidence': 0.8889723420143127, 'keypoints': {'left_eye': (52, 115), 'right_eye': (56, 115), 'nose': (51, 117), 'mouth_left': (52, 121), 'mouth_right': (55, 121)}}], [{'box': [128, 64, 10, 16], 'confidence': 0.9563508033752441, 'keypoints': {'left_eye': (127, 69), 'right_eye': (131, 68), 'nose': (127, 73), 'mouth_left': (129, 77), 'mouth_right': (132, 76)}}, {'box': [198, 72, 10, 19], 'confidence': 0.8957076072692871, 'keypoints': {'left_eye': (198, 79), 'right_eye': (202, 79), 'nose': (197, 83), 'mouth_left': (199, 88), 'mouth_right': (202, 87)}}, {'box': [10, 76, 12, 23], 'confidence': 0.8844919204711914, 'keypoints': {'left_eye': (17, 83), 'right_eye': (21, 83), 'nose': (21, 89), 'mouth_left': (16, 94), 'mouth_right': (19, 94)}}, {'box': [107, 60, 10, 14], 'confidence': 0.8679711818695068, 'keypoints': {'left_eye': (108, 66), 'right_eye': (112, 64), 'nose': (111, 68), 'mouth_left': (112, 71), 'mouth_right': (115, 69)}}], [{'box': [23, 51, 9, 12], 'confidence': 0.9976623058319092, 'keypoints': {'left_eye': (25, 54), 'right_eye': (30, 54), 'nose': (28, 57), 'mouth_left': (26, 60), 'mouth_right': (29, 60)}}, {'box': [192, 41, 10, 13], 'confidence': 0.9657423496246338, 'keypoints': {'left_eye': (194, 44), 'right_eye': (199, 43), 'nose': (197, 47), 'mouth_left': (195, 51), 'mouth_right': (199, 51)}}, {'box': [126, 48, 9, 10], 'confidence': 0.7603866457939148, 'keypoints': {'left_eye': (128, 50), 'right_eye': (133, 50), 'nose': (130, 52), 'mouth_left': (128, 55), 'mouth_right': (132, 55)}}]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_datasets as tfds\n",
    "# from my_wider_face import MyWiderFace\n",
    "\n",
    "# # Create an instance of your dataset\n",
    "# dataset_builder = MyWiderFace()\n",
    "\n",
    "# # Download and prepare the dataset\n",
    "# dataset_builder.download_and_prepare()\n",
    "\n",
    "# # Load the dataset\n",
    "# datasets = dataset_builder.as_dataset(split=['test'])\n",
    "\n",
    "\n",
    "# # Manually register your dataset\n",
    "# # tfds.core.DatasetBuilder.register_dataset(MyWiderFace)\n",
    "\n",
    "# # # Load the dataset\n",
    "# # # Replace 'wider_face' with the correct dataset name if it's different\n",
    "# # wider_face_dataset, dataset_info = tfds.load(\n",
    "# #     'my_wider_face',\n",
    "# #     with_info=True,\n",
    "# #     split=['train', 'validation', 'test'],\n",
    "# # )\n",
    "\n",
    "# # # Explore the dataset\n",
    "# # print(dataset_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
